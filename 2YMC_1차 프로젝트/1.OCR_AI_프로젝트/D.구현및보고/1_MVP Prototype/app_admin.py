import os, json, re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from PIL import Image

# =========================
# í™˜ê²½ ì„¤ì •
# =========================
load_dotenv()
DATA_ROOT = Path(os.getenv("DATA_ROOT", "./data/users")).resolve()

st.set_page_config(page_title="YMCë³´í—˜ì‚¬ ì§ì›ìš© â€“ ê³ ê° ë¬¸ì„œ ì¡°íšŒ", page_icon="ğŸ—‚ï¸", layout="wide")
st.title("ğŸ—‚ï¸ ê³ ê° ë¬¸ì„œ ì¡°íšŒ/í™•ì¸ ëŒ€ì‹œë³´ë“œ")

# =========================
# ìœ í‹¸ & ì¸ë±ì„œ
# =========================
SYSTEM_FILES = {"ocr_text.txt", "classification.json"}

def parse_ts(ts_folder: Path) -> datetime:
    # í´ë”ëª…: YYYYMMDD_HHMMSS
    try:
        return datetime.strptime(ts_folder.name, "%Y%m%d_%H%M%S")
    except Exception:
        # í´ë”ëª…ì´ ë‹¤ë¥´ë©´ í´ë°±: ìˆ˜ì • ì‹œê°
        return datetime.fromtimestamp(ts_folder.stat().st_mtime)

def read_classification(fp: Path) -> Dict[str, Any]:
    if not fp.exists():
        return {}
    try:
        return json.loads(fp.read_text(encoding="utf-8"))
    except Exception:
        return {}

def first_user_file(folder: Path) -> Path | None:
    # ê³ ê°ì´ ì˜¬ë¦° 'ì›ë³¸ íŒŒì¼' (ì‹œìŠ¤í…œ ìƒì„±ë¬¼ ì œì™¸)
    for p in folder.iterdir():
        if p.is_file() and p.name not in SYSTEM_FILES:
            return p
    return None

def safe_read_text(fp: Path) -> str:
    if not fp.exists():
        return ""
    try:
        return fp.read_text(encoding="utf-8")
    except Exception:
        return ""

@st.cache_data(show_spinner=False)
def build_index(root: Path) -> pd.DataFrame:
    rows: List[Dict[str, Any]] = []
    if not root.exists():
        return pd.DataFrame(rows)

    for user_dir in sorted(root.iterdir()):
        if not user_dir.is_dir():
            continue
        customer_id = user_dir.name
        for ts_dir in sorted(user_dir.iterdir(), key=parse_ts, reverse=True):
            if not ts_dir.is_dir():
                continue
            ts = parse_ts(ts_dir)
            cls = read_classification(ts_dir / "classification.json")
            doc_type = cls.get("doc_type", "")
            confidence = cls.get("confidence", None)
            key_fields = cls.get("key_fields", {}) or {}
            name = key_fields.get("name", "")
            date = key_fields.get("date", "")
            amount = key_fields.get("amount", "")
            policy = key_fields.get("policy_number", "")

            user_file = first_user_file(ts_dir)
            ocr_text = safe_read_text(ts_dir / "ocr_text.txt")
            rows.append({
                "ê³ ê°ID": customer_id,
                "ì—…ë¡œë“œì‹œê°": ts,
                "ë¬¸ì„œìœ í˜•": doc_type,
                "ì‹ ë¢°ë„": confidence,
                "ê³ ê°ëª…(ì¶”ì¶œ)": name,
                "ì¼ì(ì¶”ì¶œ)": date,
                "ì›ë³¸íŒŒì¼": str(user_file) if user_file else "",
                "OCRí…ìŠ¤íŠ¸ê²½ë¡œ": str((ts_dir / "ocr_text.txt").resolve()),
                "ë¶„ë¥˜JSONê²½ë¡œ": str((ts_dir / "classification.json").resolve()),
            })
    df = pd.DataFrame(rows)
    if not df.empty:
        df.sort_values(["ì—…ë¡œë“œì‹œê°"], ascending=False, inplace=True)
        df.reset_index(drop=True, inplace=True)
    return df

# =========================
# ì¸ë±ì‹± & ì‚¬ì´ë“œë°” í•„í„°
# =========================
with st.spinner("ì¸ë±ì‹± ì¤‘..."):
    df = build_index(DATA_ROOT)

if st.sidebar.button("ìƒˆë¡œê³ ì¹¨"):
    build_index.clear()
    st.rerun()

if df.empty:
    st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë£¨íŠ¸ í´ë”ì— ì—…ë¡œë“œ ê¸°ë¡ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”)")
    st.stop()

with st.sidebar:
    st.header("ğŸ” í•„í„°")
    custs = ["(ì „ì²´)"] + sorted(df["ê³ ê°ID"].unique().tolist())
    sel_cust = st.selectbox("ê³ ê° ì„ íƒ", custs)

    doc_types = ["(ì „ì²´)"] + sorted([x for x in df["ë¬¸ì„œìœ í˜•"].dropna().unique().tolist() if x])
    sel_type = st.selectbox("ë¬¸ì„œ ìœ í˜•", doc_types)

    st.caption("ì‹ ë¢°ë„(0~1)")
    min_conf, max_conf = st.slider("ì‹ ë¢°ë„ ë²”ìœ„", 0.0, 1.0, (0.0, 1.0), step=0.05)

    q = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (ê³ ê°ëª…/ì¼ì)")

    refresh = st.button("ğŸ”„ ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨", use_container_width=True)
    if refresh:
        build_index.clear()
        df = build_index(DATA_ROOT)
        st.rerun()  # âœ… ìµœì‹  Streamlitì—ì„œëŠ” ì´ë ‡ê²Œ ë³€ê²½

fdf = df.copy()
if sel_cust != "(ì „ì²´)":
    fdf = fdf[fdf["ê³ ê°ID"] == sel_cust]
if sel_type != "(ì „ì²´)":
    fdf = fdf[fdf["ë¬¸ì„œìœ í˜•"] == sel_type]
fdf = fdf[(fdf["ì‹ ë¢°ë„"].fillna(0) >= min_conf) & (fdf["ì‹ ë¢°ë„"].fillna(0) <= max_conf)]

if q:
    q = q.strip()
    mask = pd.Series(False, index=fdf.index)
    for col in ["ê³ ê°ëª…(ì¶”ì¶œ)", "ì¼ì(ì¶”ì¶œ)"]:
        mask |= fdf[col].fillna("").str.contains(q, case=False, regex=False)
    fdf = fdf[mask]

st.subheader(f"ëª©ë¡ ({len(fdf):,}ê±´)")
st.dataframe(
    fdf[["ê³ ê°ID", "ì—…ë¡œë“œì‹œê°", "ë¬¸ì„œìœ í˜•", "ì‹ ë¢°ë„", "ê³ ê°ëª…(ì¶”ì¶œ)", "ì¼ì(ì¶”ì¶œ)"]],
    use_container_width=True, height=400
)

# =========================
# ìƒì„¸ ë³´ê¸°
# =========================
st.subheader("ìƒì„¸ ë³´ê¸°")
if len(fdf) == 0:
    st.info("ì¢Œì¸¡ í•„í„°ë¥¼ ì¡°ì •í•´ ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
else:
    # ìµœì‹  1ê±´ ê¸°ë³¸ ì„ íƒ
    options = [f"[{r['ê³ ê°ID']}] {r['ì—…ë¡œë“œì‹œê°']} Â· {r['ë¬¸ì„œìœ í˜•']} Â· {Path(r['ì›ë³¸íŒŒì¼']).name if r['ì›ë³¸íŒŒì¼'] else 'ì›ë³¸ì—†ìŒ'}"
               for _, r in fdf.iterrows()]
    idx = st.selectbox("ë¬¸ì„œ ì„ íƒ", range(len(options)), format_func=lambda i: options[i])
    row = fdf.iloc[idx]

    c1, c2 = st.columns([1,1])
    with c1:
        st.markdown("**ë©”íƒ€/ë¶„ë¥˜ ì •ë³´**")
        meta = {
            "ê³ ê°ID": row["ê³ ê°ID"],
            "ì—…ë¡œë“œì‹œê°": row["ì—…ë¡œë“œì‹œê°"],
            "ë¬¸ì„œìœ í˜•": row["ë¬¸ì„œìœ í˜•"],
            "ì‹ ë¢°ë„": row["ì‹ ë¢°ë„"],
            "ê³ ê°ëª…(ì¶”ì¶œ)": row["ê³ ê°ëª…(ì¶”ì¶œ)"],
            "ì¼ì(ì¶”ì¶œ)": row["ì¼ì(ì¶”ì¶œ)"],
            "ê¸ˆì•¡(ì¶”ì¶œ)": row["ê¸ˆì•¡(ì¶”ì¶œ)"],
            "ì¦ê¶Œë²ˆí˜¸(ì¶”ì¶œ)": row["ì¦ê¶Œë²ˆí˜¸(ì¶”ì¶œ)"],
        }
        st.table(pd.DataFrame(meta, index=["ê°’"]).T)

        # ë¶„ë¥˜ JSON í”„ë¦¬ë·°
        try:
            cls_json = json.loads(Path(row["ë¶„ë¥˜JSONê²½ë¡œ"]).read_text(encoding="utf-8"))
            with st.expander("ë¶„ë¥˜ Raw JSON ë³´ê¸°", expanded=False):
                st.json(cls_json)
        except Exception:
            st.info("ë¶„ë¥˜ JSONì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with c2:
        st.markdown("**ì›ë³¸/í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
        if row["ì›ë³¸íŒŒì¼"] and Path(row["ì›ë³¸íŒŒì¼"]).exists():
            p = Path(row["ì›ë³¸íŒŒì¼"])
            if p.suffix.lower() in [".png", ".jpg", ".jpeg"]:
                st.image(str(p), caption=p.name, use_column_width=True)
            else:
                st.caption(f"ì›ë³¸: {p.name} (ë¯¸ë¦¬ë³´ê¸° ë¯¸ì§€ì› í™•ì¥ì)")
                st.download_button("ì›ë³¸ ë‹¤ìš´ë¡œë“œ", data=p.read_bytes(), file_name=p.name)
        else:
            st.info("ì›ë³¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # OCR í…ìŠ¤íŠ¸
        txt_path = Path(row["OCRí…ìŠ¤íŠ¸ê²½ë¡œ"])
        if txt_path.exists():
            with st.expander("OCR í…ìŠ¤íŠ¸ ì—´ê¸°", expanded=False):
                st.text_area("OCR í…ìŠ¤íŠ¸", txt_path.read_text(encoding="utf-8"), height=250)
                st.download_button("OCR í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", data=txt_path.read_text(encoding="utf-8"), file_name="ocr_text.txt")
        else:
            st.info("OCR í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# ë‚´ë³´ë‚´ê¸° (CSV)
# =========================
st.divider()
csv = fdf.to_csv(index=False).encode("utf-8-sig")
st.download_button("ğŸ“¥ í•„í„°ëœ ëª©ë¡ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="claims_admin_list.csv")