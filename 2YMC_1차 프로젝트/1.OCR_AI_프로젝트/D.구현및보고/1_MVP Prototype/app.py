import os, io, json, time, re, uuid, shutil, requests, cv2
from datetime import datetime
from pathlib import Path
from PIL import Image
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# =========================
# í™˜ê²½/ì„¤ì •
# =========================
load_dotenv()
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
OPENAI_API_KEY  = os.getenv("OPENAI_API_KEY")
DATA_ROOT       = Path(os.getenv("DATA_ROOT", "./data/users")).resolve()
OCR_ENDPOINT    = "https://api.upstage.ai/v1/document-digitization"
GPT_MODEL       = "gpt-4o-mini"   # í•„ìš”ì‹œ ë‹¤ë¥¸ ëª¨ë¸ë¡œ êµì²´

assert UPSTAGE_API_KEY, "í™˜ê²½ë³€ìˆ˜ UPSTAGE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤(.env í™•ì¸)."
assert OPENAI_API_KEY,  "í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤(.env í™•ì¸)."

client = OpenAI(api_key=OPENAI_API_KEY)

DOC_TYPES = [
    "ë³´í—˜ê¸ˆì²­êµ¬ì„œ",
    "ì§„ë‹¨ì„œ",
    "ì…í‡´ì›í™•ì¸ì„œ",
    "ì²˜ë°©ì „",
    "ì‚¬ê³ ê²½ìœ„ì„œ",
    "ìˆ˜ë¦¬ê²¬ì ì„œ",
    "ì‚¬ë§ì§„ë‹¨ì„œ",
    "ê¸°íƒ€ ë¬¸ì„œ"
]

# =========================
# ìœ í‹¸
# =========================
def ensure_user_folder(customer_id: str) -> Path:
    """ê³ ê°ë³„/ì—…ë¡œë“œíšŒì°¨ë³„ í´ë” ìƒì„±"""
    safe_id = re.sub(r"[^0-9A-Za-zê°€-í£_-]", "_", customer_id.strip())
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    folder = DATA_ROOT / safe_id / ts
    folder.mkdir(parents=True, exist_ok=True)
    return folder

def save_uploaded_file(file, dst_path: Path) -> Path:
    with open(dst_path, "wb") as f:
        f.write(file.read())
    return dst_path

def preprocess_image_to_png(src_path: Path) -> Path:
    """ê°„ë‹¨ ì „ì²˜ë¦¬(ê·¸ë ˆì´/ì˜¤ì¸  ì´ì§„í™”) PNGë¡œ ì €ì¥"""
    img = cv2.imdecode(
        np.fromfile(str(src_path), dtype="uint8"),
        cv2.IMREAD_COLOR
    ) if src_path.suffix.lower() not in [".png", ".jpg", ".jpeg"] else cv2.imread(str(src_path))
    if img is None:
        # PIL fallback
        pil = Image.open(src_path).convert("RGB")
        img = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (3,3), 0)
    _, thr = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
    out = src_path.with_suffix(".proc.png")
    cv2.imwrite(str(out), thr)
    return out

def run_upstage_ocr(image_path: Path) -> dict:
    """Upstage OCR í˜¸ì¶œ -> {text, ...}"""
    with open(image_path, "rb") as f:
        files = {"document": f}
        data = {"model": "ocr"}
        headers = {"Authorization": f"Bearer {UPSTAGE_API_KEY}"}
        res = requests.post(OCR_ENDPOINT, headers=headers, files=files, data=data, timeout=60)
        res.raise_for_status()
        return res.json()

def classify_with_gpt(ocr_text: str) -> dict:
    """
    GPTë¡œ ë¬¸ì„œìœ í˜• ë¶„ë¥˜ + í•µì‹¬ í•„ë“œ ì¶”ì¶œ.
    JSONìœ¼ë¡œ ê°•ì œ ë°˜í™˜.
    """
    system_prompt = (
        "ë‹¹ì‹ ì€ ë³´í—˜ ë¬¸ì„œ ë¶„ë¥˜/ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìê°€ ì œê³µí•œ OCR í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì„œ ìœ í˜•ì„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”: "
        f"{', '.join(DOC_TYPES)}. "
        "ê°€ëŠ¥í•˜ë©´ í•µì‹¬ í•„ë“œ(ì´ë¦„, ìƒë…„ì›”ì¼, ë‚ ì§œ, ê¸ˆì•¡, ì¦ê¶Œ/ê³„ì•½ë²ˆí˜¸, ë³‘ì›/ê¸°ê´€ëª…, ê³„ì¢Œì •ë³´ ë“±)ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. "
        "ì •í™•ë„(confidence)ëŠ” 0~1 ì‚¬ì´ ì‹¤ìˆ˜ë¡œ ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
    )
    user_prompt = f"""
[OCR_TEXT BEGIN]
{ocr_text[:20000]}
[OCR_TEXT END]

ë°˜í™˜ í˜•ì‹(JSON):
{{
  "doc_type": "<ìœ„ ëª©ë¡ ì¤‘ í•˜ë‚˜>",
  "confidence": 0.0,
  "key_fields": {{
      "name": "...",
      "dob": "...",
      "date": "...",
      "amount": "...",
      "policy_number": "...",
      "hospital": "...",
      "account": "..."
  }},
  "rationale": "ê°„ë‹¨ ê·¼ê±°"
}}
    """.strip()

    resp = client.chat.completions.create(
        model=GPT_MODEL,
        temperature=0.1,
        messages=[
            {"role":"system", "content": system_prompt},
            {"role":"user", "content": user_prompt}
        ]
    )
    content = resp.choices[0].message.content
    try:
        data = json.loads(content)
    except Exception:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•ˆì „ ë˜í¼
        data = {"doc_type":"ê¸°íƒ€","confidence":0.0,"key_fields":{},"rationale":"parse_failed","raw":content}
    return data

# numpy import (ì§€ì—° ì‚¬ìš© ëŒ€ë¹„)
import numpy as np

# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="ë³´í—˜ ì²­êµ¬ ì„œë¥˜ ì—…ë¡œë“œ Â· OCR Â· ë¶„ë¥˜", page_icon="ğŸ§¾", layout="wide")

st.title("ğŸ§¾ YMC ë³´í—˜ ì²­êµ¬")
st.caption("ë¹ ë¥¸ ì²­êµ¬ëŠ” YMC ë³´í—˜")

with st.form("uploader", clear_on_submit=False):
    col1, col2 = st.columns([1,2])
    with col1:
        customer_id = st.text_input("ê³ ê° ID ë˜ëŠ” ì´ë¦„", placeholder="ì˜ˆ: í™ê¸¸ë™_ID")
    with col2:
        uploaded = st.file_uploader("ë³´í—˜ ì²­êµ¬ ì„œë¥˜ ì—…ë¡œë“œ", type=["png","jpg","jpeg","pdf","tif","tiff"])
    submitted = st.form_submit_button("ì—…ë¡œë“œ ë° ë¶„ë¥˜ ì‹¤í–‰")

if submitted:
    # âœ… 0) ìœ íš¨ì„± ê²€ì‚¬: íŒŒì¼ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ(ì–´ë–¤ ê¸°ë¡/í´ë” ìƒì„±ë„ X)
    if uploaded is None:
        st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.stop()  # â† ì•„ë˜ ì½”ë“œ ì „ë¶€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ë¡œê·¸/í´ë” ìƒì„± ë°©ì§€)

    if not customer_id.strip():
        st.warning("ê³ ê° ID ë˜ëŠ” ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()


    # 1) ê³ ê° í´ë” ìƒì„±
    user_folder = ensure_user_folder(customer_id)
    st.info(f"ğŸ“‚ ê³ ê° í´ë” ìƒì„±: {user_folder}")

    # 2) ì›ë³¸ ì €ì¥
    original_path = user_folder / uploaded.name
    save_uploaded_file(uploaded, original_path)
    st.success(f"ì›ë³¸ ì €ì¥ ì™„ë£Œ: {original_path.name}")

    # 3) ì´ë¯¸ì§€/í˜ì´ì§€ ì „ì²˜ë¦¬ (ë‹¨ìˆœí™”: ì´ë¯¸ì§€í˜•ë§Œ ì²˜ë¦¬, PDFëŠ” ê·¸ëŒ€ë¡œ OCR ì‹œë„)
    targets = []
    if original_path.suffix.lower() in [".png",".jpg",".jpeg",".tif",".tiff",".bmp"]:
        proc = preprocess_image_to_png(original_path)
        targets = [proc]
    else:
        # PDF/ê¸°íƒ€ëŠ” ì „ì²˜ë¦¬ ìƒëµí•˜ê³  ê·¸ëŒ€ë¡œ ë³´ëƒ„ (Upstageê°€ ë‚´ë¶€ ì²˜ë¦¬)
        targets = [original_path]

    # 4) Upstage OCR í˜¸ì¶œ(ë³µìˆ˜ page/íŒŒì¼ì´ë©´ í•©ì¹˜ê¸°)
    ocr_texts = []
    for t in targets:
        try:
            res = run_upstage_ocr(t)
            ocr_texts.append(res.get("text",""))
        except Exception as e:
            st.error(f"OCR ì‹¤íŒ¨: {e}")
            st.stop()

    merged_text = "\n\n".join(ocr_texts).strip()

    # 5) GPT ë¶„ë¥˜
    with st.spinner("GPTë¡œ ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜ ì¤‘..."):
        classify = classify_with_gpt(merged_text)

    # 6) ê²°ê³¼ ì €ì¥
    text_path = user_folder / "ocr_text.txt"
    json_path = user_folder / "classification.json"
    text_path.write_text(merged_text, encoding="utf-8")
    json_path.write_text(json.dumps(classify, ensure_ascii=False, indent=2), encoding="utf-8")

    # 7) ê²°ê³¼ í‘œì‹œ
    st.subheader("ë¶„ë¥˜ ê²°ê³¼")
    st.json(classify)
    st.download_button("OCR í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", data=merged_text, file_name="ocr_text.txt")
    st.download_button("ë¶„ë¥˜ JSON ë‹¤ìš´ë¡œë“œ", data=json.dumps(classify, ensure_ascii=False, indent=2), file_name="classification.json")

    # ê°„ë‹¨ ë¯¸ë¦¬ë³´ê¸°
    if original_path.suffix.lower() in [".png",".jpg",".jpeg",".tif",".tiff",".bmp"]:
        st.image(str(original_path), caption="ì›ë³¸ ë¯¸ë¦¬ë³´ê¸°", use_column_width=True)