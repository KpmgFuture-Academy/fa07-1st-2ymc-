import os, json, re, shutil, stat
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from PIL import Image

# =========================
# í™˜ê²½ ì„¤ì •
# =========================
load_dotenv()
DATA_ROOT = Path(os.getenv("DATA_ROOT", "./data/users")).resolve()

st.set_page_config(page_title="YMCë³´í—˜ì‚¬ ì§ì›ìš© â€“ ê³ ê° ë¬¸ì„œ ì¡°íšŒ", page_icon="ğŸ—‚ï¸", layout="wide")
st.title("ğŸ—‚ï¸ ê³ ê° ë¬¸ì„œ ì¡°íšŒ/í™•ì¸ ëŒ€ì‹œë³´ë“œ")


# =========================
# ê°„ë‹¨í•œ ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ
# =========================
ADMIN_PASSWORD = "1234"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "admin_authenticated" not in st.session_state:
    st.session_state.admin_authenticated = False

if not st.session_state.admin_authenticated:
    st.title("ğŸ” ê´€ë¦¬ì ë¡œê·¸ì¸")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

    if st.button("ë¡œê·¸ì¸"):
        if password == ADMIN_PASSWORD:
            st.session_state.admin_authenticated = True
            st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ! ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            st.rerun()  # âœ… ìµœì‹  Streamlitì—ì„œëŠ” ì´ë ‡ê²Œ!
        else:
            st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    st.stop()


# =========================
# ìœ í‹¸ & ì¸ë±ì„œ
# =========================
# âœ… ë‹¤ì¤‘ íŒŒì¼ êµ¬ì¡°(ê³ ê°ìš©) ë° ë ˆê±°ì‹œ êµ¬ì¡°(ë‹¨ì¼ íŒŒì¼) ëª¨ë‘ ì§€ì›
SYSTEM_FILES = {
    "summary.json",               # íšŒì°¨ ìš”ì•½ (ë‹¤ì¤‘ íŒŒì¼)
}
SYSTEM_SUFFIXES = {
    ".ocr_text.txt",              # íŒŒì¼ë³„ OCR í…ìŠ¤íŠ¸
    ".classification.json",       # íŒŒì¼ë³„ ë¶„ë¥˜ JSON
    ".proc.png",                  # ì „ì²˜ë¦¬ ì‚°ì¶œë¬¼
}
LEGACY_FILES = {"ocr_text.txt", "classification.json"}  # ë ˆê±°ì‹œ ë‹¨ì¼ êµ¬ì¡°


def find_original_by_stem(ts_dir: Path, stem: str) -> Path | None:
    cand_exts = [".png",".jpg",".jpeg",".bmp",".tif",".tiff",".pdf",".doc",".docx",".hwp"]
    for ext in cand_exts:
        p = ts_dir / f"{stem}{ext}"
        if p.exists() and not is_system_artifact(p):
            return p
    for p in ts_dir.iterdir():
        if p.is_file() and p.stem == stem and not is_system_artifact(p):
            return p
    return None

def parse_ts(ts_folder: Path) -> datetime:
    try:
        return datetime.strptime(ts_folder.name, "%Y%m%d_%H%M%S")
    except Exception:
        return datetime.fromtimestamp(ts_folder.stat().st_mtime)

def read_classification(fp: Path) -> Dict[str, Any]:
    if not fp.exists():
        return {}
    try:
        return json.loads(fp.read_text(encoding="utf-8"))
    except Exception:
        return {}

def safe_read_text(fp: Path) -> str:
    if not fp.exists():
        return ""
    try:
        return fp.read_text(encoding="utf-8")
    except Exception:
        return ""

def is_system_artifact(p: Path) -> bool:
    if p.name in SYSTEM_FILES or p.name in LEGACY_FILES:
        return True
    for suf in SYSTEM_SUFFIXES:
        if p.name.endswith(suf):
            return True
    return False

def list_original_files(folder: Path) -> list[Path]:
    files = []
    for p in folder.iterdir():
        if p.is_file() and not is_system_artifact(p):
            files.append(p)
    return sorted(files)

def read_summary(fp: Path) -> list[dict]:
    if not fp.exists():
        return []
    try:
        data = json.loads(fp.read_text(encoding="utf-8"))
        return data if isinstance(data, list) else []
    except Exception:
        return []

@st.cache_data(show_spinner=False)
def build_index(root: Path) -> pd.DataFrame:
    """
    ìš°ì„ ìˆœìœ„
    1) summary.json (ë‹¤ì¤‘ íŒŒì¼ íšŒì°¨)
    2) *.classification.json / *.ocr_text.txt í˜ì–´ ìë™ íƒìƒ‰
    3) legacy: classification.json / ocr_text.txt (ë‹¨ì¼ íŒŒì¼)
    """
    rows: List[Dict[str, Any]] = []
    if not root.exists():
        return pd.DataFrame(rows)

    for user_dir in sorted(root.iterdir()):
        if not user_dir.is_dir():
            continue
        customer_id = user_dir.name

        for ts_dir in sorted(user_dir.iterdir(), key=parse_ts, reverse=True):
            if not ts_dir.is_dir():
                continue
            ts = parse_ts(ts_dir)

            # 1) summary.json ìš°ì„ 
            summ = read_summary(ts_dir / "summary.json")
            if summ:
                for item in summ:
                    cls = item.get("classification", {}) or {}
                    kf  = cls.get("key_fields", {}) or {}
                    orig_path = (ts_dir / item.get("file","")).resolve()
                    ocr_path  = (ts_dir / item.get("ocr_text_path","")).resolve()
                    cls_path  = (ts_dir / item.get("classification_path","")).resolve()
                    rows.append({
                        "ê³ ê°ID": customer_id,
                        "ì—…ë¡œë“œì‹œê°": ts,
                        "ë¬¸ì„œìœ í˜•": cls.get("doc_type", ""),
                        "ì‹ ë¢°ë„": cls.get("confidence", None),
                        "ê³ ê°ëª…(ì¶”ì¶œ)": kf.get("name", ""),
                        "ì¼ì(ì¶”ì¶œ)": kf.get("date", ""),
                        "ì›ë³¸íŒŒì¼": str(orig_path) if orig_path.exists() else "",
                        "OCRí…ìŠ¤íŠ¸ê²½ë¡œ": str(ocr_path),
                        "ë¶„ë¥˜JSONê²½ë¡œ": str(cls_path),
                    })
                continue  # ì´ íšŒì°¨ ì²˜ë¦¬ ì™„ë£Œ

            # 2) íŒŒì¼ë³„ í˜ì–´ ìë™ íƒìƒ‰ (*.classification.json ê¸°ì¤€)
            cls_files = list(ts_dir.glob("*.classification.json"))
            if cls_files:
                for cls_fp in cls_files:
                    stem = cls_fp.name[:-len(".classification.json")]
                    ocr_fp = ts_dir / f"{stem}.ocr_text.txt"
                    orig_fp = find_original_by_stem(ts_dir, stem)

                    cls = read_classification(cls_fp)
                    kf  = cls.get("key_fields", {}) or {}
                    rows.append({
                        "ê³ ê°ID": customer_id,
                        "ì—…ë¡œë“œì‹œê°": ts,
                        "ë¬¸ì„œìœ í˜•": cls.get("doc_type",""),
                        "ì‹ ë¢°ë„": cls.get("confidence", None),
                        "ê³ ê°ëª…(ì¶”ì¶œ)": kf.get("name",""),
                        "ì¼ì(ì¶”ì¶œ)": kf.get("date",""),
                        "ì›ë³¸íŒŒì¼": str(orig_fp.resolve()) if orig_fp else "",
                        "OCRí…ìŠ¤íŠ¸ê²½ë¡œ": str(ocr_fp.resolve()),
                        "ë¶„ë¥˜JSONê²½ë¡œ": str(cls_fp.resolve()),
                    })
                continue  # ì´ íšŒì°¨ ì²˜ë¦¬ ì™„ë£Œ

            # 3) ë ˆê±°ì‹œ ë‹¨ì¼ íŒŒì¼ í´ë°±
            cls_legacy = ts_dir / "classification.json"
            ocr_legacy = ts_dir / "ocr_text.txt"
            if cls_legacy.exists() or ocr_legacy.exists():
                originals = [p for p in ts_dir.iterdir() if p.is_file() and not is_system_artifact(p)]
                user_file = originals[0] if originals else None

                cls = read_classification(cls_legacy)
                kf  = cls.get("key_fields", {}) or {}
                rows.append({
                    "ê³ ê°ID": customer_id,
                    "ì—…ë¡œë“œì‹œê°": ts,
                    "ë¬¸ì„œìœ í˜•": cls.get("doc_type",""),
                    "ì‹ ë¢°ë„": cls.get("confidence", None),
                    "ê³ ê°ëª…(ì¶”ì¶œ)": kf.get("name",""),
                    "ì¼ì(ì¶”ì¶œ)": kf.get("date",""),
                    "ì›ë³¸íŒŒì¼": str(user_file.resolve()) if user_file else "",
                    "OCRí…ìŠ¤íŠ¸ê²½ë¡œ": str(ocr_legacy.resolve()),
                    "ë¶„ë¥˜JSONê²½ë¡œ": str(cls_legacy.resolve()),
                })
            # else: ì‚°ì¶œë¬¼ ì—†ìœ¼ë©´ ìŠ¤í‚µ

    df = pd.DataFrame(rows)
    if not df.empty:
        df.sort_values(["ì—…ë¡œë“œì‹œê°"], ascending=False, inplace=True)
        df.reset_index(drop=True, inplace=True)
    return df

# =========================
# ì¸ë±ì‹± & ì‚¬ì´ë“œë°” í•„í„°
# =========================

if st.sidebar.button("ìƒˆë¡œê³ ì¹¨"):
    build_index.clear()
    st.rerun()

with st.sidebar:
    st.divider()
    st.subheader("ì´ë™ ë©”ë‰´")

    CUSTOMER_URL = "http://localhost:8501/"
    if st.button("ğŸ§¾ ê³ ê°ìš© í™”ë©´ìœ¼ë¡œ ì´ë™"):
        st.markdown(
            f"""
            <meta http-equiv="refresh" content="0; url={CUSTOMER_URL}">
            """,
            unsafe_allow_html=True
        )
        st.info("ê³ ê°ìš© í™”ë©´ìœ¼ë¡œ ì´ë™ ì¤‘ì…ë‹ˆë‹¤...")

with st.spinner("ì¸ë±ì‹± ì¤‘..."):
    df = build_index(DATA_ROOT)


if df.empty:
    st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë£¨íŠ¸ í´ë”ì— ì—…ë¡œë“œ ê¸°ë¡ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”)")
    st.stop()

with st.sidebar:
    st.header("ğŸ” í•„í„°")
    custs = ["(ì „ì²´)"] + sorted(df["ê³ ê°ID"].unique().tolist())
    sel_cust = st.selectbox("ê³ ê° ì„ íƒ", custs)

    doc_types = ["(ì „ì²´)"] + sorted([x for x in df["ë¬¸ì„œìœ í˜•"].dropna().unique().tolist() if x])
    sel_type = st.selectbox("ë¬¸ì„œ ìœ í˜•", doc_types)

    st.caption("ì‹ ë¢°ë„(0~1)")
    min_conf, max_conf = st.slider("ì‹ ë¢°ë„ ë²”ìœ„", 0.0, 1.0, (0.0, 1.0), step=0.05)

    q = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (ê³ ê°ëª…/ì¼ì/íŒŒì¼ëª…)")

    refresh = st.button("ğŸ”„ ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨", use_container_width=True)
    if refresh:
        build_index.clear()
        df = build_index(DATA_ROOT)
        st.rerun()

fdf = df.copy()
if sel_cust != "(ì „ì²´)":
    fdf = fdf[fdf["ê³ ê°ID"] == sel_cust]
if sel_type != "(ì „ì²´)":
    fdf = fdf[fdf["ë¬¸ì„œìœ í˜•"] == sel_type]
fdf = fdf[(fdf["ì‹ ë¢°ë„"].fillna(0) >= min_conf) & (fdf["ì‹ ë¢°ë„"].fillna(0) <= max_conf)]

if q:
    q = q.strip()
    mask = pd.Series(False, index=fdf.index)
    for col in ["ê³ ê°ëª…(ì¶”ì¶œ)", "ì¼ì(ì¶”ì¶œ)"]:
        mask |= fdf[col].fillna("").str.contains(q, case=False, regex=False)
    # íŒŒì¼ëª…ë„ ê²€ìƒ‰ì— í¬í•¨
    if "ì›ë³¸íŒŒì¼" in fdf.columns:
        mask |= fdf["ì›ë³¸íŒŒì¼"].fillna("").str.contains(q, case=False, regex=False)
    fdf = fdf[mask]

st.subheader(f"ëª©ë¡ ({len(fdf):,}ê±´)")
st.dataframe(
    fdf[["ê³ ê°ID", "ì—…ë¡œë“œì‹œê°", "ë¬¸ì„œìœ í˜•", "ì‹ ë¢°ë„", "ê³ ê°ëª…(ì¶”ì¶œ)", "ì¼ì(ì¶”ì¶œ)"]],
    use_container_width=True, height=400
)

# =========================
# ìƒì„¸ ë³´ê¸°
# =========================
st.subheader("ìƒì„¸ ë³´ê¸°")
if len(fdf) == 0:
    st.info("ì¢Œì¸¡ í•„í„°ë¥¼ ì¡°ì •í•´ ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
else:
    options = [f"[{r['ê³ ê°ID']}] {r['ì—…ë¡œë“œì‹œê°']} Â· {r['ë¬¸ì„œìœ í˜•']} Â· {Path(r['ì›ë³¸íŒŒì¼']).name if r['ì›ë³¸íŒŒì¼'] else 'ì›ë³¸ì—†ìŒ'}"
               for _, r in fdf.iterrows()]
    idx = st.selectbox("ë¬¸ì„œ ì„ íƒ", range(len(options)), format_func=lambda i: options[i])
    row = fdf.iloc[idx]

    c1, c2 = st.columns([1,1])
    with c1:
        st.markdown("**ë©”íƒ€/ë¶„ë¥˜ ì •ë³´**")
        meta = {
            "ê³ ê°ID": row["ê³ ê°ID"],
            "ì—…ë¡œë“œì‹œê°": row["ì—…ë¡œë“œì‹œê°"],
            "ë¬¸ì„œìœ í˜•": row["ë¬¸ì„œìœ í˜•"],
            "ì‹ ë¢°ë„": row["ì‹ ë¢°ë„"],
            "ê³ ê°ëª…(ì¶”ì¶œ)": row["ê³ ê°ëª…(ì¶”ì¶œ)"],
            "ì¼ì(ì¶”ì¶œ)": row["ì¼ì(ì¶”ì¶œ)"],
        }
        st.table(pd.DataFrame(meta, index=["ê°’"]).T)

        # ë¶„ë¥˜ JSON í”„ë¦¬ë·°
        try:
            cls_json = json.loads(Path(row["ë¶„ë¥˜JSONê²½ë¡œ"]).read_text(encoding="utf-8"))
            with st.expander("ë¶„ë¥˜ Raw JSON ë³´ê¸°", expanded=False):
                st.json(cls_json)
        except Exception:
            st.info("ë¶„ë¥˜ JSONì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with c2:
        st.markdown("**ì›ë³¸/í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
        if row["ì›ë³¸íŒŒì¼"] and Path(row["ì›ë³¸íŒŒì¼"]).exists():
            p = Path(row["ì›ë³¸íŒŒì¼"])
            ext = p.suffix.lower()
            if ext in [".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff"]:
                st.image(str(p), caption=p.name, use_container_width=True)
            else:
                st.caption(f"ì›ë³¸: {p.name} (ë¯¸ë¦¬ë³´ê¸° ë¯¸ì§€ì› í™•ì¥ì)")
            st.download_button("ì›ë³¸ ë‹¤ìš´ë¡œë“œ", data=p.read_bytes(), file_name=p.name)
        else:
            st.info("ì›ë³¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # OCR í…ìŠ¤íŠ¸
        txt_path = Path(row["OCRí…ìŠ¤íŠ¸ê²½ë¡œ"])
        if txt_path.exists():
            with st.expander("OCR í…ìŠ¤íŠ¸ ì—´ê¸°", expanded=False):
                txt = txt_path.read_text(encoding="utf-8")
                st.text_area("OCR í…ìŠ¤íŠ¸", txt, height=250)
                st.download_button("OCR í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", data=txt, file_name=txt_path.name)
        else:
            st.info("OCR í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# ë‚´ë³´ë‚´ê¸° (CSV)
# =========================
st.divider()
csv = fdf.to_csv(index=False).encode("utf-8-sig")
st.download_button("ğŸ“¥ í•„í„°ëœ ëª©ë¡ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="claims_admin_list.csv")